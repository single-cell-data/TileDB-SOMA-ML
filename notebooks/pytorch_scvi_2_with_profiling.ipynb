{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an scVI model using Census data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a scalable approach to training an [scVI](https://docs.scvi-tools.org/en/latest/user_guide/models/scvi.html) model on Census data. The [scvi-tools](https://scvi-tools.org/) library is built around [PyTorch Lightning](https://lightning.ai/docs/pytorch/stable/). [TileDB-SOMA-ML](https://github.com/single-cell-data/TileDB-SOMA-ML) assists with streaming Census query results to PyTorch in batches, allowing for training datasets larger than available RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. Training the model\n",
    "2. Generate cell embeddings\n",
    "3. Analyzing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model \n",
    "\n",
    "Let's start by importing the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "St3art\n"
     ]
    }
   ],
   "source": [
    "print(\"St3art\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/miniforge3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from typing import Any, Dict, List\n",
    "import torch\n",
    "import cellxgene_census\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import tiledbsoma as soma\n",
    "from tiledbsoma_ml import SCVIDataModule\n",
    "import torch\n",
    "from cellxgene_census.experimental.pp import highly_variable_genes\n",
    "from lightning import LightningDataModule\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s %(message)s\")\n",
    "logging.getLogger(\"tiledbsoma_ml.dataset\").setLevel(logging.DEBUG)\n",
    "\n",
    "import time\n",
    "from torch.profiler import schedule, ProfilerActivity, tensorboard_trace_handler\n",
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "import os, torch\n",
    "\n",
    "logdir = \"./log/scvi_prof\"                     # one folder per run\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now prepare the necessary parameters for running a training pass of the model.\n",
    "\n",
    "For this notebook, we'll use a stable version of the Census:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also do two types of filtering.\n",
    "\n",
    "For **cells**, we will apply a filter to only select primary cells, with at least 300 expressed genes (nnz >= 300). For notebook demonstration purposes, we will also apply a tissue filtering so that the training can happen on a laptop. The same approach can be used on datasets much larger than available RAM. (A GPU is recommended, though.)\n",
    "\n",
    "For **genes**, we will apply a filter so that only the top 8000 highly variable genes (HVG) are included in the training. This is a commonly used dimensionality reduction approach and is recommended on production models as well.\n",
    "\n",
    "Let's define a few parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"mus_musculus\"\n",
    "obs_value_filter = 'is_primary_data == True and tissue_general in [\"pancreas\", \"kidney\"] and nnz >= 300'\n",
    "top_n_hvg = 8000\n",
    "hvg_batch = [\"assay\", \"suspension_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_URI = \"/home/ec2-user/new/mm_pan_kidney_subset_soma\"       # same path you wrote above\n",
    "# census = cellxgene_census.open_soma(uri=LOCAL_URI)\n",
    "exp = soma.open(LOCAL_URI, mode=\"r\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For HVG, we can use the `highly_variable_genes` function provided in `cellxgene_census`, which can compute HVGs in constant memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522076 obs\n",
      "KeysView(<Collection 'file:///home/ec2-user/new/mm_pan_kidney_subset_soma/ms/RNA/X' (open for 'r') (1 item)\n",
      "    'data': 'file:///home/ec2-user/new/mm_pan_kidney_subset_soma/ms/RNA/X/data' (unopened)>)\n",
      "CPU times: user 410 ms, sys: 190 ms, total: 600 ms\n",
      "Wall time: 322 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = exp.axis_query(\n",
    "    measurement_name=\"RNA\",\n",
    "    obs_query=soma.AxisQuery(value_filter=obs_value_filter),\n",
    ")\n",
    "print(f\"{query.n_obs} obs\")\n",
    "query.obs(column_names=['dataset_id']).concat().to_pandas().dataset_id.astype(str).value_counts()\n",
    "print(exp.ms[\"RNA\"].X.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 1s, sys: 1min 34s, total: 4min 36s\n",
      "Wall time: 35.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hvgs_df = highly_variable_genes(\n",
    "    query,\n",
    "    n_top_genes=top_n_hvg,\n",
    "    batch_key=hvg_batch,\n",
    "    layer=\"data\"\n",
    ")\n",
    "hv = hvgs_df.highly_variable\n",
    "hv_idx = hv[hv].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now introduce a helper class `SCVIDataModule` to connect TileDB-SOMA-ML with PyTorch Lightning. It subclasses [`LightningDataModule`](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) and:\n",
    "\n",
    "1. Uses TileDB-SOMA-ML to prepare a DataLoader for the results of a SOMA [`ExperimentAxisQuery`](https://tiledbsoma.readthedocs.io/en/1.15.0/python-tiledbsoma-experimentaxisquery.html) on the Census.\n",
    "1. Derives each cell's scVI batch label as a tuple of obs attributes: `dataset_id`, `assay`, `suspension_type`, `donor_id`.\n",
    "    * *Don't confuse each cell's label for scVI \"batch\" integration with a training data \"batch\" generated by the DataLoader.*\n",
    "1. Converts the RNA counts and batch labels to a dict of tensors for each training data batch, as scVI expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_workers': 8, 'persistent_workers': True, 'pin_memory': True}\n",
      "CPU times: user 3.02 s, sys: 495 ms, total: 3.52 s\n",
      "Wall time: 3.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(522076, 8000, 109)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hvg_query = exp.axis_query(\n",
    "    measurement_name=\"RNA\",\n",
    "    obs_query=soma.AxisQuery(value_filter=obs_value_filter),\n",
    "    var_query=soma.AxisQuery(coords=(list(hv_idx),)),\n",
    ")\n",
    "\n",
    "datamodule = SCVIDataModule(\n",
    "    hvg_query,\n",
    "    layer_name=\"data\",\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    dataloader_kwargs={\"num_workers\": 8, \"persistent_workers\": True, \"pin_memory\": True},\n",
    ")\n",
    "\n",
    "(datamodule.n_obs, datamodule.n_vars, datamodule.n_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most parameters to `SCVIDataModule` are passed through to the [`tiledbsoma_ml.ExperimentDataset`](https://single-cell-data.github.io/TileDB-SOMA-ML/#tiledbsoma_ml.ExperimentDataset) initializer; see that documentation to understand how it can be tuned.\n",
    "\n",
    "In particular, here are some parameters of interest:\n",
    "\n",
    "* `shuffle`: shuffles the result cell order, which is often advisable for model training.\n",
    "* `batch_size`: controls the size (number of cells) in each training data batch, in turn controlling memory usage.\n",
    "* `dataloader_kwargs`: [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) tuning, for example controlling parallelization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the scVI model object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 1\n",
    "n_latent = 50\n",
    "\n",
    "model = scvi.model.SCVI(\n",
    "    n_layers=n_layers,\n",
    "    n_latent=n_latent,\n",
    "    gene_likelihood=\"nb\",\n",
    "    encode_covariates=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can invoke the `.train` method which will start the training loop. For this demonstration, we'll only do a single epoch, but this should likely be increased for a production model. The scVI models hosted in CELLxGENE have been trained for 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:54:27,961 GPU available: True (cuda), used: True\n",
      "2025-07-22 15:54:27,962 TPU available: False, using: 0 TPU cores\n",
      "2025-07-22 15:54:27,962 HPU available: False, using: 0 HPUs\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "2025-07-22 15:54:28,242 ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "2025-07-22 15:54:28,623 switching torch multiprocessing start method from \"fork\" to \"spawn\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:21<00:00, 39.33s/it, v_num=1, train_loss_step=2.6e+3, train_loss_epoch=2.62e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:58:26,294 `Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:21<00:00, 40.26s/it, v_num=1, train_loss_step=2.6e+3, train_loss_epoch=2.62e+3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-22 15:58:27,787 open file: /tmp/tmpg0h50hyx/.temp.ckpt\n",
      "2025-07-22 15:58:28,017 open file: /tmp/tmpg0h50hyx/.temp.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time:  240.45036454100045\n"
     ]
    }
   ],
   "source": [
    "t0 = time.perf_counter()\n",
    "\n",
    "model.train(\n",
    "    datamodule=datamodule,\n",
    "    max_epochs=5,\n",
    "    early_stopping=False,\n",
    "    devices=-1,\n",
    "    strategy=\"ddp_notebook_find_unused_parameters_true\",\n",
    ")\n",
    "\n",
    "print(\"The time: \", time.perf_counter() - t0)\n",
    "# epoch_printer = EpochTimePrinter()\n",
    "\n",
    "# model.train(\n",
    "#     datamodule=datamodule,\n",
    "#     max_epochs=3,\n",
    "#     early_stopping=False,\n",
    "#     devices=-1,\n",
    "#     strategy=\"ddp_notebook_find_unused_parameters_true\",\n",
    "#     # callbacks=[epoch_printer],\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the trained model. As of the current writing, scvi-tools doesn't support saving a model that wasn't generated through an AnnData loader, so we'll use some custom code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = model.module.state_dict()\n",
    "var_names = hv_idx.to_numpy()\n",
    "user_attributes = model._get_user_attributes()\n",
    "user_attributes = {a[0]: a[1] for a in user_attributes if a[0][-1] == \"_\"}\n",
    "\n",
    "user_attributes.update(\n",
    "    {\n",
    "        \"n_batch\": datamodule.n_batch,\n",
    "        \"n_extra_categorical_covs\": 0,\n",
    "        \"n_extra_continuous_covs\": 0,\n",
    "        \"n_labels\": 1,\n",
    "        \"n_vars\": datamodule.n_vars,\n",
    "        \"batch_labels\": datamodule.batch_labels,\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(\"model.pt\", \"wb\") as f:\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model_state_dict\": model_state_dict,\n",
    "            \"var_names\": var_names,\n",
    "            \"attr_dict\": user_attributes,\n",
    "        },\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the model back and use it to generate cell embeddings (the latent space), which can then be used for further analysis. Loading the model similarly involves some custom code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray._reconstruct])` or the `torch.serialization.safe_globals([numpy._core.multiarray._reconstruct])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mmodel.pt\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     torch_model = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     adict = torch_model[\u001b[33m\"\u001b[39m\u001b[33mattr_dict\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m     params = adict[\u001b[33m\"\u001b[39m\u001b[33minit_params_\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mnon_kwargs\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/site-packages/torch/serialization.py:1524\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1516\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1517\u001b[39m                     opened_zipfile,\n\u001b[32m   1518\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1521\u001b[39m                     **pickle_load_args,\n\u001b[32m   1522\u001b[39m                 )\n\u001b[32m   1523\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1525\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1526\u001b[39m             opened_zipfile,\n\u001b[32m   1527\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1530\u001b[39m             **pickle_load_args,\n\u001b[32m   1531\u001b[39m         )\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray._reconstruct was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray._reconstruct])` or the `torch.serialization.safe_globals([numpy._core.multiarray._reconstruct])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "with open(\"model.pt\", \"rb\") as f:\n",
    "    torch_model = torch.load(f)\n",
    "\n",
    "    adict = torch_model[\"attr_dict\"]\n",
    "    params = adict[\"init_params_\"][\"non_kwargs\"]\n",
    "\n",
    "    n_batch = adict[\"n_batch\"]\n",
    "    n_extra_categorical_covs = adict[\"n_extra_categorical_covs\"]\n",
    "    n_extra_continuous_covs = adict[\"n_extra_continuous_covs\"]\n",
    "    n_labels = adict[\"n_labels\"]\n",
    "    n_vars = adict[\"n_vars\"]\n",
    "\n",
    "    latent_distribution = params[\"latent_distribution\"]\n",
    "    dispersion = params[\"dispersion\"]\n",
    "    n_hidden = params[\"n_hidden\"]\n",
    "    dropout_rate = params[\"dropout_rate\"]\n",
    "    gene_likelihood = params[\"gene_likelihood\"]\n",
    "\n",
    "    model = scvi.model.SCVI(\n",
    "        n_layers=params[\"n_layers\"],\n",
    "        n_latent=params[\"n_latent\"],\n",
    "        gene_likelihood=params[\"gene_likelihood\"],\n",
    "        encode_covariates=False,\n",
    "    )\n",
    "\n",
    "    module = model._module_cls(\n",
    "        n_input=n_vars,\n",
    "        n_batch=n_batch,\n",
    "        n_labels=n_labels,\n",
    "        n_continuous_cov=n_extra_continuous_covs,\n",
    "        n_cats_per_cov=None,\n",
    "        n_hidden=n_hidden,\n",
    "        n_latent=n_latent,\n",
    "        n_layers=n_layers,\n",
    "        dropout_rate=dropout_rate,\n",
    "        dispersion=dispersion,\n",
    "        gene_likelihood=gene_likelihood,\n",
    "        latent_distribution=latent_distribution,\n",
    "    )\n",
    "    model.module = module\n",
    "\n",
    "    model.module.load_state_dict(torch_model[\"model_state_dict\"])\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.to_device(device)\n",
    "    model.module.eval()\n",
    "    model.is_trained = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate cell embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now generate the cell embeddings for this model, using the `get_latent_representation` function available in scvi-tools. \n",
    "\n",
    "We can use another instance of the `SCVIDataModule` for the forward pass, so we don't need to load the whole dataset in memory. This will have shuffling disabled to make it easier to join the embeddings later. We also want to restore the list of scVI batch labels from the training data, ensuring our forward pass will map batch labels to tensors in the expected way (although this specific example would work regardless, since it reuses the same query)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_datamodule = SCVIDataModule(\n",
    "    hvg_query,\n",
    "    layer_name=\"raw\",\n",
    "    batch_labels=adict[\"batch_labels\"],\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    dataloader_kwargs={\"num_workers\": 0, \"persistent_workers\": False},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To feed the data to `get_latent_representation`, we operate `inference_datamodule` as PyTorch Lightning would during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_datamodule.setup()\n",
    "inference_dataloader = (\n",
    "    inference_datamodule.on_before_batch_transfer(batch, None) for batch in inference_datamodule.train_dataloader()\n",
    ")\n",
    "latent = model.get_latent_representation(dataloader=inference_dataloader)\n",
    "latent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully trained the model and generated embeddings using limited memory. Even on the full Census, this has been tested to run with less than 30G of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the results\n",
    "\n",
    "We will now take a look at the UMAP for the generated embedding. Note that this model was only trained for one epoch (for demo purposes), so we don't expect the UMAP to show significant integration patterns, but it is nonetheless a good way to check the overall health of the generated embedding.\n",
    "\n",
    "In order to do this, we'll use `scanpy` which accepts an AnnData object, so we'll generate one using the `get_anndata` utility function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = cellxgene_census.get_anndata(\n",
    "    census,\n",
    "    organism=experiment_name,\n",
    "    obs_value_filter=obs_value_filter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the generated embedding (stored in `latent`) in the obsm slot of the AnnData object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify cell order:\n",
    "assert np.array_equal(np.array(adata.obs[\"soma_joinid\"]), inference_datamodule.train_dataset.query_ids.obs_joinids)\n",
    "\n",
    "adata.obsm[\"scvi\"] = latent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate the neighbors and the UMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep=\"scvi\", key_added=\"scvi\")\n",
    "sc.tl.umap(adata, neighbors_key=\"scvi\")\n",
    "sc.pl.umap(adata, color=\"dataset_id\", title=\"SCVI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=\"tissue_general\", title=\"SCVI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=\"cell_type\", title=\"SCVI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
